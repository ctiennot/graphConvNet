\section{Conclusion}
This project allowed us to work on the cutting edge topic of non-euclidean CNN. Interestingly, the ideas developed here can easily be extended to be used on data defined over Manifolds, as suggested in \cite{DBLP:journals/corr/BronsteinBLSV16}, which could lead to even larger applications. It is worth noting that since the beginning of this project, two unpublished (and not reviewed by us) papers have been proposed on the topic of GCNN and GCNN Autoencoders,  \cite{2016arXiv161107308K} \cite{DBLP:journals/corr/KipfW16}. The subject is hence in active research state, which explains why few experiments were made on the best architecture existing to tackle general Neural Networks problems. Hence the results produced during this project should be interpreted regarding the relative youth of those techniques, that do not benefit from a large research corpus as classic CNNs do. Nevertheless, regarding the results we had in our experiments, we are quite confident that great achievements will be made on this subject in a very near future. 

We would like to thank our adviser and reviewer \emph{Florian Strub}, for giving us the chance to work on such an interesting subject, and for his help to tackle the \texttt{tensorflow} implementation. The code we produced as part of this project is available at \url{https://github.com/ctiennot/graphConvNet}.

