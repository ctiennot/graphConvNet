{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about reshaping a bit Alex's work (4_mnist_classifier notebook) to use the 1d-maxpooling after reindexing and also to use Chebishev coefficients for the filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/clement/Dropbox/MVA/Graphs in ML/project/graphConvNet\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys, os\n",
    "sys.path.insert(0,os.getcwd())  # add current folder to sources\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.mnist import load_mnist  # helper to load MNIST data\n",
    "from src.GraphMaxPooling import GraphMaxPooling\n",
    "from src.GraphLayers import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data, coarsening, laplacians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load mnist dataset\n",
    "training_mnist = load_mnist(dataset='training')\n",
    "testing_mnist = load_mnist(dataset='testing')\n",
    "\n",
    "training_data = numpy.reshape(training_mnist[0], [training_mnist[0].shape[0],28*28])\n",
    "training_data = training_data/255.0\n",
    "training_labels = training_mnist[1]\n",
    "training_cats = numpy.zeros([training_labels.shape[0], 10])\n",
    "for i in range(0,training_labels.shape[0]):\n",
    "    training_cats[i][training_labels[i]]=1\n",
    "    \n",
    "testing_data = numpy.reshape(testing_mnist[0], [testing_mnist[0].shape[0],28*28])\n",
    "testing_data = testing_data/255.0\n",
    "testing_labels = testing_mnist[1]\n",
    "testing_cats = numpy.zeros([testing_labels.shape[0], 10])\n",
    "for i in range(0,testing_labels.shape[0]):\n",
    "    testing_cats[i][testing_labels[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBoAAADZCAYAAACO71NWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faac3299550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the GraphMaxPooling class to build a grid and perform the coarsening\n",
    "W = GraphMaxPooling.generate_grid(*training_mnist[0][0].shape)\n",
    "foo_pooling = GraphMaxPooling(W, 4)\n",
    "foo_pooling.plot_pooled_images(training_mnist[0][0].reshape((-1,)))  # plot what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we retrieve all the new ordering and we add the virtuals nodes and reshape the signal\n",
    "# to clean matrices X_train and X_test\n",
    "\n",
    "ordering = foo_pooling.new_order\n",
    "init_dim = 28*28  # initial dimension of the images\n",
    "n_virtuals = len(ordering) - init_dim  # number of virtual nodes to add\n",
    "\n",
    "# First for X_train\n",
    "X_train = training_mnist[0].reshape((-1, init_dim))  # flatten images\n",
    "X_train = np.hstack((X_train, np.zeros((X_train.shape[0], n_virtuals))))  # add zeros for virtuals\n",
    "X_train = X_train[:, ordering]  # reorder\n",
    "\n",
    "# Then for X_test\n",
    "X_test = testing_mnist[0].reshape((-1, init_dim))  # flatten images\n",
    "X_test = np.hstack((X_test, np.zeros((X_test.shape[0], n_virtuals))))  # add zeros for virtuals\n",
    "X_test = X_test[:, ordering]  # reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 1056), including 784 true nodes and 272 virtual nodes\n",
      "X_test:  (10000, 1056), including 784 true nodes and 272 virtual nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train: {}, including {} true nodes and {} virtual nodes\".format(X_train.shape, init_dim, n_virtuals))\n",
    "print(\"X_test:  {}, including {} true nodes and {} virtual nodes\".format(X_test.shape, init_dim, n_virtuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1056, 1056), (528, 528), (264, 264), (132, 132), (66, 66)]\n"
     ]
    }
   ],
   "source": [
    "# Now we retrieve all the Laplacians\n",
    "laplacians = foo_pooling.get_laplacians(how='unn')\n",
    "laplacians = [np.array(L, dtype=np.float32) for L in laplacians]  # cast to float32\n",
    "print([L.shape for L in laplacians])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's all we need. Now we will (in the next section) build our network, as if we were dealing with 1d signals (for the max-pooling part). The only tricky part is to implement the filters using Chebyshev. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our CNN we use the objects from the GraphLayers module. The GraphConv objects take as input a symbolic tensor which must be the output attribute from the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We instantiate Session object\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input = tf.placeholder(tf.float32, [None, laplacians[0].shape[0]])  # X_train or X_test\n",
    "X_input_ = tf.expand_dims(X_input, 2)  # add depth dimension\n",
    "\n",
    "GConv1 = GraphConv(X_input_, K=5, F=10, L=laplacians[0])\n",
    "\n",
    "GConv1.max_pool()\n",
    "\n",
    "GConv2 = GraphConv(GConv1.output, K=5, F=2, L=laplacians[1])  # 2 filters on the 10 previous filters = depth 20\n",
    "\n",
    "GConv2.max_pool()\n",
    "\n",
    "GConv3 = GraphConv(GConv2.output, K=5, F=2, L=laplacians[2])  # 2 filters on the 20 previous filters = depth 40\n",
    "\n",
    "GConv3.max_pool()\n",
    "\n",
    "#GConv4 = GraphConv(GConv3.output, K=5, F=2, L=laplacians[3])  # 2 filters on the 40 previous filters = depth 80\n",
    "\n",
    "#GConv4.max_pool()\n",
    "\n",
    "dense1 = Dense(GConv3.output, u=256)\n",
    "dense1.relu()\n",
    "\n",
    "dense2 = Dense(dense1.output, u=10)\n",
    "dense2.sofmax()\n",
    "\n",
    "ygcnn = dense2.output\n",
    "\n",
    "# placeholder for the labels\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train phase (copied from 4_mnist_classifier.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    -tf.reduce_sum(y * tf.log(ygcnn), reduction_indices=[1]))\n",
    "weights = tf.trainable_variables()\n",
    "weights_decay = tf.add_n([tf.nn.l2_loss(v) for v in weights])*0.001\n",
    "loss = tf.add(cross_entropy, weights_decay)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(ygcnn,1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We initialize the values\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.09, testing accuracy 0.12\n",
      "step 100, training accuracy 0.71, testing accuracy 0.83\n",
      "step 200, training accuracy 0.79, testing accuracy 0.85\n",
      "step 300, training accuracy 0.89, testing accuracy 0.86\n",
      "step 400, training accuracy 0.89, testing accuracy 0.92\n",
      "step 500, training accuracy 0.94, testing accuracy 0.87\n",
      "step 600, training accuracy 0.9, testing accuracy 0.95\n",
      "step 700, training accuracy 0.95, testing accuracy 0.92\n",
      "step 800, training accuracy 0.91, testing accuracy 0.93\n",
      "step 900, training accuracy 0.94, testing accuracy 0.9\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for i in range(1000):\n",
    "    idx = numpy.random.permutation(training_data.shape[0])\n",
    "    idx = idx[0:100]\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X_input:X_train[idx], y: training_cats[idx]})\n",
    "        idx = numpy.random.permutation(testing_data.shape[0])\n",
    "        idx = idx[0:100]\n",
    "        test_accuracy = accuracy.eval(feed_dict={X_input: X_test[idx], y:testing_cats[idx]})\n",
    "        print(\"step %d, training accuracy %g, testing accuracy %g\"%(i, train_accuracy, test_accuracy))\n",
    "    train_step.run(feed_dict={X_input: X_train[idx], y: training_cats[idx]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
